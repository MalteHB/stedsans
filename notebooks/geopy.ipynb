{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for examining how ```geopy``` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install geopy\n",
    "!pip -q install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "\n",
    "from src.stedsans.nlp.ner.predict import NamedEntityRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = NamedEntityRecognition().tag_sentence(\"Malte bor på Jægergårdsgade 23 Aarhus C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_loc_idx = d.get(\"tag\").index(\"B-LOC\")\n",
    "loc = d.get(\"word\")[b_loc_idx]\n",
    "print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_list = []\n",
    "counter = 0\n",
    "for tag in d.get(\"tag\"):\n",
    "    if \"LOC\" in tag or \"ORG\" in tag:\n",
    "        loc_list.append(d.get(\"word\")[counter])\n",
    "    counter += 1\n",
    "    \n",
    "loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d.get(\"tag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_list = []\n",
    "for idx, tag in enumerate(d.get(\"tag\")):\n",
    "    if idx != len(d.get(\"tag\")):\n",
    "        if \"B-LOC\" in tag:\n",
    "            loc_list.append(d.get(\"word\")[idx])\n",
    "        elif \"I-LOC\" in tag:\n",
    "            loc_list.append(d.get(\"word\")[idx])\n",
    "        elif \"B-ORG\" in tag:\n",
    "            loc_list.append(d.get(\"word\")[idx])\n",
    "        elif \"I-ORG\" in tag:\n",
    "            loc_list.append(d.get(\"word\")[idx])\n",
    "loc_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_result = []\n",
    "\n",
    "entities = []         # Named entity instances will go here.\n",
    "current_entity = []   # Tokens that are part of the current entity will go here.\n",
    "\n",
    "last_tag = None       # We'll use this to check whether a token is part of the same entity as the previous.\n",
    "\n",
    "for idx, tag in enumerate(d.get(\"tag\")):\n",
    "\n",
    "    token = d.get(\"word\")[idx]\n",
    "    \n",
    "    if tag == 'O' or last_tag != tag:\t# We've reached the end of the current entity.\n",
    "    \t# If that entity had a real tag (not 'O' or None), then save it.\n",
    "        if last_tag != 'O' and last_tag != None:\n",
    "        \t# We save the list of tokens in this named entity, along with its tag, as a tuple.\n",
    "            #if tag[0] == \n",
    "        \t#  string.join() converts the list of tokens into a string.\n",
    "            entities.append((' '.join(current_entity), last_tag))\n",
    "        current_entity = []\t# Reset for a new entity.\n",
    "    last_tag = tag\t\t\t# Keep track of the current entity tag; see lines 10 and 12.\n",
    "    current_entity.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_result = []\n",
    "\n",
    "current_entity_tokens = []         # Named entity instances will go here.\n",
    "current_entity = []   # Tokens that are part of the current entity will go here.\n",
    "\n",
    "last_tag = None       # We'll use this to check whether a token is part of the same entity as the previous.\n",
    "\n",
    "for idx, tag in enumerate(d.get(\"tag\")):\n",
    "\n",
    "    token = d.get(\"word\")[idx]\n",
    "    \n",
    "    if tag == 'O':\t# We've reached the end of the current entity.\n",
    "        continue\n",
    "    if tag.startswith(\"B-\"):\n",
    "         # ... if we have a previous entity in the buffer, store it in the result list\n",
    "        if current_entity is not None:\n",
    "            collapsed_result.append(\n",
    "                (\" \".join(current_entity_tokens), current_entity))\n",
    "\n",
    "        current_entity = tag[2:]\n",
    "        # The new entity has so far only one token\n",
    "        current_entity_tokens = [token]\n",
    "    # If the entity continues ...\n",
    "    elif tag == \"I-\" + current_entity:\n",
    "        # Just add the token buffer\n",
    "        current_entity_tokens.append(token)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tag order.\")\n",
    "\n",
    "# The last entity is still in the buffer, so add it to the result\n",
    "# ... but only if there were some entity at all\n",
    "if current_entity is not None:\n",
    "    collapsed_result.append(\n",
    "        (\" \".join(current_entity_tokens), current_entity))\n",
    "    \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse(ner_result):\n",
    "    # List with the result\n",
    "    collapsed_result = []\n",
    "\n",
    "    # Buffer for tokens belonging to the most recent entity\n",
    "    current_entity_tokens = []\n",
    "    current_entity = None\n",
    "\n",
    "    # Iterate over the tagged tokens\n",
    "    for token, tag in ner_result:\n",
    "        if tag == \"O\":\n",
    "            continue\n",
    "        # If an enitity span starts ...\n",
    "        if tag.startswith(\"B-\"):\n",
    "            # ... if we have a previous entity in the buffer, store it in the result list\n",
    "            if current_entity is not None:\n",
    "                collapsed_result.append(\n",
    "                    (\" \".join(current_entity_tokens), current_entity))\n",
    "\n",
    "            current_entity = tag[2:]\n",
    "            # The new entity has so far only one token\n",
    "            current_entity_tokens = [token]\n",
    "        # If the entity continues ...\n",
    "        elif tag == \"I-\" + current_entity:\n",
    "            # Just add the token buffer\n",
    "            current_entity_tokens.append(token)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tag order.\")\n",
    "\n",
    "    # The last entity is still in the buffer, so add it to the result\n",
    "    # ... but only if there were some entity at all\n",
    "    if current_entity is not None:\n",
    "        collapsed_result.append(\n",
    "            (\" \".join(current_entity_tokens), current_entity))\n",
    "            \n",
    "collapse(entities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []         # Named entity instances will go here.\n",
    "current_entity = []   # Tokens that are part of the current entity will go here.\n",
    "\n",
    "last_tag = None       # We'll use this to check whether a token is part of the same entity as the previous.\n",
    "\n",
    "for i in xrange(len(tagged_tokens)):    # Evaluate each token, in order.\n",
    "\t# Separate the token from its tag, so that we can evaluate them separately.\n",
    "    token, tag = tagged_tokens[i]       \n",
    "\n",
    "    if tag == 'O' or last_tag != tag:\t# We've reached the end of the current entity.\n",
    "    \t# If that entity had a real tag (not 'O' or None), then save it.\n",
    "        if last_tag != 'O' and last_tag != None:\n",
    "        \t# We save the list of tokens in this named entity, along with its tag, as a tuple.\n",
    "        \t#  string.join() converts the list of tokens into a string.\n",
    "            entities.append((' '.join(current_entity), last_tag))\n",
    "        current_entity = []\t# Reset for a new entity.\n",
    "    last_tag = tag\t\t\t# Keep track of the current entity tag; see lines 10 and 12.\n",
    "    current_entity.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d.get(\"tag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \" \".join(loc_list)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "location = locator.geocode(loc)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = location.latitude\n",
    "long = location.longitude\n",
    "print(f\"The coordinates for the lovely city of {loc} are: \\nLatitude = {lat}, Longitude = {long}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = folium.Map(\n",
    "    location=[lat,long],\n",
    "    tiles='cartodbpositron',\n",
    "    zoom_start=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUCK SHIT I MADE IT WORK :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('stedsans': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acd28d2a827aad0e67cb3f8c90e5b37f8a3392cf46d2aca771dd209cceff19d7"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
